{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions\n",
      "(57, 15)\n",
      "(57, 1700)\n",
      "(57, 4556)\n",
      "(57, 208)\n",
      "(57, 4064)\n",
      "(57,)\n"
     ]
    }
   ],
   "source": [
    "X_body2 = pd.read_csv(\"./features/2_body_phog_features.csv\").iloc[:, 1:]\n",
    "X_face2 = pd.read_csv(\"./features/2_facial_lbp_features.csv\").iloc[:, 1:]\n",
    "X_geo2 = pd.read_csv(\"./features/2_geo_features.csv\").iloc[:, 1:]\n",
    "X_cont2 = pd.read_csv(\"./features/2_context_features.csv\").iloc[:, 1:]\n",
    "X_cent2 = pd.read_csv(\"./features/2_CENTRIST.csv\").iloc[:, 1:]\n",
    "Y_valence2 = pd.read_csv(\"./labels/2_valence.csv\")[\"V\"]\n",
    "Y_arousal2 = pd.read_csv(\"./labels/2_arousal.csv\")[\"A\"]\n",
    "Y_combined2 = pd.read_csv(\"./labels/2_combined.csv\")[\"AV\"]\n",
    "X_body2 = X_body2.loc[Y_arousal2.notnull()]\n",
    "X_face2 = X_face2.loc[Y_arousal2.notnull()]\n",
    "X_geo2 = X_geo2.loc[Y_arousal2.notnull()]\n",
    "X_cont2 = X_cont2.loc[Y_arousal2.notnull()]\n",
    "X_cent2 = X_cent2.loc[Y_arousal2.notnull()]\n",
    "Y_arousal2 = Y_arousal2.loc[Y_arousal2.notnull()]\n",
    "\n",
    "print \"Dimensions\"\n",
    "print X_cont2.shape\n",
    "print X_body2.shape\n",
    "print X_geo2.shape\n",
    "print X_face2.shape\n",
    "print X_cent2.shape\n",
    "print Y_arousal2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(X, Y, filename):\n",
    "    print(\"Classifying: %s\" % filename)\n",
    "    print\n",
    "    # Split the dataset in two equal parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=0.5, random_state=0)\n",
    "\n",
    "    # Set the parameters by cross-validation\n",
    "    score = 'accuracy'\n",
    "\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "#     print\n",
    "\n",
    "    params = {\"C\": [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]}\n",
    "    clf = GridSearchCV(LinearSVC(random_state=42), params, cv=10, scoring=\"accuracy\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "#     print(\"Best parameters set found on development set:\")\n",
    "#     print\n",
    "#     print(clf.best_params_)\n",
    "#     print\n",
    "\n",
    "#     print(\"Detailed classification report:\")\n",
    "#     print\n",
    "#     print(\"The model is trained on the full development set.\")\n",
    "#     print(\"The scores are computed on the full evaluation set.\")\n",
    "#     print\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Accuracy: %f\" % accuracy_score(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print\n",
    "\n",
    "    return (y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fusion(X, Y):\n",
    "    fused_result = 0\n",
    "    for i in range(len(Y)):\n",
    "        row = list(newX[i])\n",
    "        bins = dict((x, row.count(x)) for x in row)\n",
    "        if(max(bins, key=bins.get) == Y.iloc[i]):\n",
    "            fused_result += 1\n",
    "    return float(fused_result) / len(Y_A_cont2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Faces: Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 2_arousal_cont\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.38      0.90      0.53        10\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.80      0.25      0.38        16\n",
      "\n",
      "avg / total       0.57      0.45      0.39        29\n",
      "\n",
      "Accuracy: 0.448276\n",
      "[[ 9  0  1]\n",
      " [ 3  0  0]\n",
      " [12  0  4]]\n",
      "\n",
      "Classifying: 2_arousal_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.38      0.50      0.43        10\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.62      0.62      0.62        16\n",
      "\n",
      "avg / total       0.48      0.52      0.49        29\n",
      "\n",
      "Accuracy: 0.517241\n",
      "[[ 5  0  5]\n",
      " [ 2  0  1]\n",
      " [ 6  0 10]]\n",
      "\n",
      "Classifying: 2_arousal_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.50      0.20      0.29        10\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.56      0.88      0.68        16\n",
      "\n",
      "avg / total       0.48      0.55      0.48        29\n",
      "\n",
      "Accuracy: 0.551724\n",
      "[[ 2  0  8]\n",
      " [ 0  0  3]\n",
      " [ 2  0 14]]\n",
      "\n",
      "Classifying: 2_arousal_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.00      0.00      0.00        10\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.55      1.00      0.71        16\n",
      "\n",
      "avg / total       0.30      0.55      0.39        29\n",
      "\n",
      "Accuracy: 0.551724\n",
      "[[ 0  0 10]\n",
      " [ 0  0  3]\n",
      " [ 0  0 16]]\n",
      "\n",
      "Classifying: 2_arousal_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.00      0.00      0.00        10\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.55      1.00      0.71        16\n",
      "\n",
      "avg / total       0.30      0.55      0.39        29\n",
      "\n",
      "Accuracy: 0.551724\n",
      "[[ 0  0 10]\n",
      " [ 0  0  3]\n",
      " [ 0  0 16]]\n",
      "\n",
      "Accuracy after fusion: 0.586207\n"
     ]
    }
   ],
   "source": [
    "Y_A_cont2, y = classify(X_cont2, Y_arousal2, \"2_arousal_cont\")\n",
    "Y_A_cent2, y = classify(X_cent2, Y_arousal2, \"2_arousal_cent\")\n",
    "Y_A_geo2, y = classify(X_geo2, Y_arousal2, \"2_arousal_geo\")\n",
    "Y_A_face2, y = classify(X_face2, Y_arousal2, \"2_arousal_lbp\")\n",
    "Y_A_body2, y = classify(X_body2, Y_arousal2, \"2_arousal_phog\")\n",
    "# Fused\n",
    "newX = np.column_stack((Y_A_cont2, Y_A_cent2, Y_A_geo2, Y_A_face2, Y_A_body2))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Faces: Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_body2 = pd.read_csv(\"./features/2_body_phog_features.csv\").iloc[:, 1:]\n",
    "X_face2 = pd.read_csv(\"./features/2_facial_lbp_features.csv\").iloc[:, 1:]\n",
    "X_geo2 = pd.read_csv(\"./features/2_geo_features.csv\").iloc[:, 1:]\n",
    "X_cont2 = pd.read_csv(\"./features/2_context_features.csv\").iloc[:, 1:]\n",
    "X_cent2 = pd.read_csv(\"./features/2_CENTRIST.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 2_valence_cont\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.29      0.22      0.25         9\n",
      "        Neu       0.26      1.00      0.41         8\n",
      "          P       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.12      0.26      0.15        38\n",
      "\n",
      "Accuracy: 0.263158\n",
      "[[ 2  7  0]\n",
      " [ 0  8  0]\n",
      " [ 5 16  0]]\n",
      "\n",
      "Classifying: 2_valence_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         9\n",
      "        Neu       0.29      0.50      0.36         8\n",
      "          P       0.56      0.43      0.49        21\n",
      "\n",
      "avg / total       0.37      0.34      0.35        38\n",
      "\n",
      "Accuracy: 0.342105\n",
      "[[0 4 5]\n",
      " [2 4 2]\n",
      " [6 6 9]]\n",
      "\n",
      "Classifying: 2_valence_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.30      0.33      0.32         9\n",
      "        Neu       0.08      0.12      0.10         8\n",
      "          P       0.73      0.52      0.61        21\n",
      "\n",
      "avg / total       0.49      0.39      0.43        38\n",
      "\n",
      "Accuracy: 0.394737\n",
      "[[ 3  6  0]\n",
      " [ 3  1  4]\n",
      " [ 4  6 11]]\n",
      "\n",
      "Classifying: 2_valence_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         9\n",
      "        Neu       0.00      0.00      0.00         8\n",
      "          P       0.55      1.00      0.71        21\n",
      "\n",
      "avg / total       0.31      0.55      0.39        38\n",
      "\n",
      "Accuracy: 0.552632\n",
      "[[ 0  0  9]\n",
      " [ 0  0  8]\n",
      " [ 0  0 21]]\n",
      "\n",
      "Classifying: 2_valence_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00         9\n",
      "        Neu       0.00      0.00      0.00         8\n",
      "          P       0.55      1.00      0.71        21\n",
      "\n",
      "avg / total       0.31      0.55      0.39        38\n",
      "\n",
      "Accuracy: 0.552632\n",
      "[[ 0  0  9]\n",
      " [ 0  0  8]\n",
      " [ 0  0 21]]\n",
      "\n",
      "Accuracy after fusion: 0.689655\n"
     ]
    }
   ],
   "source": [
    "Y_V_cont2, y = classify(X_cont2, Y_valence2, \"2_valence_cont\")\n",
    "Y_V_cent2, y = classify(X_cent2, Y_valence2, \"2_valence_cent\")\n",
    "Y_V_geo2, y = classify(X_geo2, Y_valence2, \"2_valence_geo\")\n",
    "Y_V_face2, y = classify(X_face2, Y_valence2, \"2_valence_lbp\")\n",
    "Y_V_body2, y = classify(X_body2, Y_valence2, \"2_valence_phog\")\n",
    "# Fused\n",
    "newX = np.column_stack((Y_V_cont2, Y_V_cent2, Y_V_geo2, Y_V_face2, Y_V_body2))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Faces: Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 2_combined_cont\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:960: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         4\n",
      "         HP       0.50      0.20      0.29        10\n",
      "         LN       0.00      0.00      0.00         0\n",
      "         MN       0.00      0.00      0.00         5\n",
      "         MP       0.50      0.09      0.15        11\n",
      "        Neu       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.28      0.08      0.12        38\n",
      "\n",
      "Accuracy: 0.078947\n",
      "[[0 0 3 0 1 0]\n",
      " [0 2 7 0 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 1 4 0 0 0]\n",
      " [0 0 9 1 1 0]\n",
      " [0 1 7 0 0 0]]\n",
      "\n",
      "Classifying: 2_combined_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         4\n",
      "         HP       0.40      0.20      0.27        10\n",
      "         LN       0.00      0.00      0.00         0\n",
      "         MN       0.00      0.00      0.00         5\n",
      "         MP       0.31      0.36      0.33        11\n",
      "        Neu       0.27      0.50      0.35         8\n",
      "\n",
      "avg / total       0.25      0.26      0.24        38\n",
      "\n",
      "Accuracy: 0.263158\n",
      "[[0 0 0 0 1 3]\n",
      " [2 2 0 0 4 2]\n",
      " [0 0 0 0 0 0]\n",
      " [0 1 0 0 3 1]\n",
      " [1 0 1 0 4 5]\n",
      " [1 2 0 0 1 4]]\n",
      "\n",
      "Classifying: 2_combined_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.33      0.25      0.29         4\n",
      "         HP       0.00      0.00      0.00        10\n",
      "         LN       0.00      0.00      0.00         0\n",
      "         MN       0.00      0.00      0.00         5\n",
      "         MP       0.23      0.45      0.30        11\n",
      "        Neu       0.14      0.12      0.13         8\n",
      "\n",
      "avg / total       0.13      0.18      0.15        38\n",
      "\n",
      "Accuracy: 0.184211\n",
      "[[1 0 0 0 2 1]\n",
      " [0 0 0 0 8 2]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 3 1]\n",
      " [1 1 2 0 5 2]\n",
      " [0 1 1 1 4 1]]\n",
      "\n",
      "Classifying: 2_combined_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         4\n",
      "         HP       0.00      0.00      0.00        10\n",
      "         MN       0.00      0.00      0.00         5\n",
      "         MP       0.29      1.00      0.45        11\n",
      "        Neu       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.08      0.29      0.13        38\n",
      "\n",
      "Accuracy: 0.289474\n",
      "[[ 0  0  0  4  0]\n",
      " [ 0  0  0 10  0]\n",
      " [ 0  0  0  5  0]\n",
      " [ 0  0  0 11  0]\n",
      " [ 0  0  0  8  0]]\n",
      "\n",
      "Classifying: 2_combined_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         4\n",
      "         HP       0.00      0.00      0.00        10\n",
      "         MN       0.00      0.00      0.00         5\n",
      "         MP       0.32      0.91      0.48        11\n",
      "        Neu       0.14      0.12      0.13         8\n",
      "\n",
      "avg / total       0.12      0.29      0.17        38\n",
      "\n",
      "Accuracy: 0.289474\n",
      "[[ 0  0  0  4  0]\n",
      " [ 0  0  0  7  3]\n",
      " [ 0  0  0  3  2]\n",
      " [ 0  0  0 10  1]\n",
      " [ 0  0  0  7  1]]\n",
      "\n",
      "Accuracy after fusion: 0.379310\n"
     ]
    }
   ],
   "source": [
    "Y_AV_cont2, y = classify(X_cont2, Y_combined2, \"2_combined_cont\")\n",
    "Y_AV_cent2, y = classify(X_cent2, Y_combined2, \"2_combined_cent\")\n",
    "Y_AV_geo2, y = classify(X_geo2, Y_combined2, \"2_combined_geo\")\n",
    "Y_AV_face2, y = classify(X_face2, Y_combined2, \"2_combined_lbp\")\n",
    "Y_AV_body2, y = classify(X_body2, Y_combined2, \"2_combined_phog\")\n",
    "# Fused\n",
    "newX = np.column_stack((Y_AV_cont2, Y_AV_cent2, Y_AV_geo2, Y_AV_face2, Y_AV_body2))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions\n",
      "(48, 22)\n",
      "(48, 2550)\n",
      "(48, 6834)\n",
      "(48, 312)\n",
      "(48, 4064)\n",
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "X_body3 = pd.read_csv(\"./features/3_body_phog_features.csv\").iloc[:, 1:]\n",
    "X_face3 = pd.read_csv(\"./features/3_facial_lbp_features.csv\").iloc[:, 1:]\n",
    "X_geo3 = pd.read_csv(\"./features/3_geo_features.csv\").iloc[:, 1:]\n",
    "X_cont3 = pd.read_csv(\"./features/3_context_features.csv\").iloc[:, 1:]\n",
    "X_cent3 = pd.read_csv(\"./features/3_CENTRIST.csv\").iloc[:, 1:]\n",
    "Y_valence3 = pd.read_csv(\"./labels/3_valence.csv\")[\"V\"]\n",
    "Y_arousal3 = pd.read_csv(\"./labels/3_arousal.csv\")[\"A\"]\n",
    "Y_combined3 = pd.read_csv(\"./labels/3_combined.csv\")[\"AV\"]\n",
    "X_body3 = X_body3.loc[Y_arousal3.notnull()]\n",
    "X_face3 = X_face3.loc[Y_arousal3.notnull()]\n",
    "X_geo3 = X_geo3.loc[Y_arousal3.notnull()]\n",
    "X_cont3 = X_cont3.loc[Y_arousal3.notnull()]\n",
    "X_cent3 = X_cent3.loc[Y_arousal3.notnull()]\n",
    "Y_arousal3 = Y_arousal3.loc[Y_arousal3.notnull()]\n",
    "\n",
    "print \"Dimensions\"\n",
    "print X_cont3.shape\n",
    "print X_body3.shape\n",
    "print X_geo3.shape\n",
    "print X_face3.shape\n",
    "print X_cent3.shape\n",
    "print Y_arousal3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3 Faces: Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 3_arousal_cont\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.48      0.91      0.62        11\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.67      0.20      0.31        10\n",
      "\n",
      "avg / total       0.50      0.50      0.41        24\n",
      "\n",
      "Accuracy: 0.500000\n",
      "[[10  0  1]\n",
      " [ 3  0  0]\n",
      " [ 8  0  2]]\n",
      "\n",
      "Classifying: 3_arousal_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.58      0.64      0.61        11\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.42      0.50      0.45        10\n",
      "\n",
      "avg / total       0.44      0.50      0.47        24\n",
      "\n",
      "Accuracy: 0.500000\n",
      "[[7 0 4]\n",
      " [0 0 3]\n",
      " [5 0 5]]\n",
      "\n",
      "Classifying: 3_arousal_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.57      0.36      0.44        11\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.53      0.90      0.67        10\n",
      "\n",
      "avg / total       0.48      0.54      0.48        24\n",
      "\n",
      "Accuracy: 0.541667\n",
      "[[4 0 7]\n",
      " [2 0 1]\n",
      " [1 0 9]]\n",
      "\n",
      "Classifying: 3_arousal_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.00      0.00      0.00        11\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.42      1.00      0.59        10\n",
      "\n",
      "avg / total       0.17      0.42      0.25        24\n",
      "\n",
      "Accuracy: 0.416667\n",
      "[[ 0  0 11]\n",
      " [ 0  0  3]\n",
      " [ 0  0 10]]\n",
      "\n",
      "Classifying: 3_arousal_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.00      0.00      0.00        11\n",
      "          L       0.00      0.00      0.00         3\n",
      "          M       0.42      1.00      0.59        10\n",
      "\n",
      "avg / total       0.17      0.42      0.25        24\n",
      "\n",
      "Accuracy: 0.416667\n",
      "[[ 0  0 11]\n",
      " [ 0  0  3]\n",
      " [ 0  0 10]]\n",
      "\n",
      "Accuracy after fusion: 0.379310\n"
     ]
    }
   ],
   "source": [
    "Y_A_cont3, y = classify(X_cont3, Y_arousal3, \"3_arousal_cont\")\n",
    "Y_A_cent3, y = classify(X_cent3, Y_arousal3, \"3_arousal_cent\")\n",
    "Y_A_geo3, y = classify(X_geo3, Y_arousal3, \"3_arousal_geo\")\n",
    "Y_A_face3, y = classify(X_face3, Y_arousal3, \"3_arousal_lbp\")\n",
    "Y_A_body3, y = classify(X_body3, Y_arousal3, \"3_arousal_phog\")\n",
    "# Fused\n",
    "newX = np.column_stack((Y_A_cont3, Y_A_cent3, Y_A_geo3, Y_A_face3, Y_A_body3))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Faces: Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_body3 = pd.read_csv(\"./features/3_body_phog_features.csv\").iloc[:, 1:]\n",
    "X_face3 = pd.read_csv(\"./features/3_facial_lbp_features.csv\").iloc[:, 1:]\n",
    "X_geo3 = pd.read_csv(\"./features/3_geo_features.csv\").iloc[:, 1:]\n",
    "X_cont3 = pd.read_csv(\"./features/3_context_features.csv\").iloc[:, 1:]\n",
    "X_cent3 = pd.read_csv(\"./features/3_CENTRIST.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 3_valence_cont\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.32      0.55      0.40        11\n",
      "        Neu       0.00      0.00      0.00        11\n",
      "          P       0.43      0.55      0.48        11\n",
      "\n",
      "avg / total       0.25      0.36      0.29        33\n",
      "\n",
      "Accuracy: 0.363636\n",
      "[[6 0 5]\n",
      " [8 0 3]\n",
      " [5 0 6]]\n",
      "\n",
      "Classifying: 3_valence_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.50      0.27      0.35        11\n",
      "        Neu       0.00      0.00      0.00        11\n",
      "          P       0.35      0.73      0.47        11\n",
      "\n",
      "avg / total       0.28      0.33      0.27        33\n",
      "\n",
      "Accuracy: 0.333333\n",
      "[[3 2 6]\n",
      " [2 0 9]\n",
      " [1 2 8]]\n",
      "\n",
      "Classifying: 3_valence_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.17      0.18      0.17        11\n",
      "        Neu       0.38      0.27      0.32        11\n",
      "          P       0.38      0.45      0.42        11\n",
      "\n",
      "avg / total       0.31      0.30      0.30        33\n",
      "\n",
      "Accuracy: 0.303030\n",
      "[[2 4 5]\n",
      " [5 3 3]\n",
      " [5 1 5]]\n",
      "\n",
      "Classifying: 3_valence_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.25      0.09      0.13        11\n",
      "        Neu       1.00      0.09      0.17        11\n",
      "          P       0.32      0.82      0.46        11\n",
      "\n",
      "avg / total       0.52      0.33      0.25        33\n",
      "\n",
      "Accuracy: 0.333333\n",
      "[[ 1  0 10]\n",
      " [ 1  1  9]\n",
      " [ 2  0  9]]\n",
      "\n",
      "Classifying: 3_valence_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.40      0.55      0.46        11\n",
      "        Neu       0.25      0.09      0.13        11\n",
      "          P       0.36      0.45      0.40        11\n",
      "\n",
      "avg / total       0.34      0.36      0.33        33\n",
      "\n",
      "Accuracy: 0.363636\n",
      "[[6 2 3]\n",
      " [4 1 6]\n",
      " [5 1 5]]\n",
      "\n",
      "Accuracy after fusion: 0.379310\n"
     ]
    }
   ],
   "source": [
    "Y_V_cont3, y = classify(X_cont3, Y_valence3, \"3_valence_cont\")\n",
    "Y_V_cent3, y = classify(X_cent3, Y_valence3, \"3_valence_cent\")\n",
    "Y_V_geo3, y = classify(X_geo3, Y_valence3, \"3_valence_geo\")\n",
    "Y_V_face3, y = classify(X_face3, Y_valence3, \"3_valence_lbp\")\n",
    "Y_V_body3, y = classify(X_body3, Y_valence3, \"3_valence_phog\")\n",
    "# Fused\n",
    "newX = np.column_stack((Y_V_cont3, Y_V_cent3, Y_V_geo3, Y_V_face3, Y_V_body3))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Faces: Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 3_combined_cont\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         6\n",
      "         HP       0.00      0.00      0.00         4\n",
      "         LN       0.00      0.00      0.00         2\n",
      "         MN       0.11      0.33      0.17         3\n",
      "         MP       0.29      1.00      0.45         7\n",
      "        Neu       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.07      0.24      0.11        33\n",
      "\n",
      "Accuracy: 0.242424\n",
      "[[0 0 0 1 5 0]\n",
      " [0 0 0 2 2 0]\n",
      " [0 0 0 1 1 0]\n",
      " [0 0 0 1 2 0]\n",
      " [0 0 0 0 7 0]\n",
      " [0 0 0 4 7 0]]\n",
      "\n",
      "Classifying: 3_combined_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         6\n",
      "         HP       0.00      0.00      0.00         4\n",
      "         LN       0.00      0.00      0.00         2\n",
      "         MN       0.00      0.00      0.00         3\n",
      "         MP       0.24      0.71      0.36         7\n",
      "        Neu       0.17      0.09      0.12        11\n",
      "\n",
      "avg / total       0.11      0.18      0.11        33\n",
      "\n",
      "Accuracy: 0.181818\n",
      "[[0 0 0 1 3 2]\n",
      " [0 0 0 0 3 1]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 0 3 0]\n",
      " [0 0 1 0 5 1]\n",
      " [2 2 0 0 6 1]]\n",
      "\n",
      "Classifying: 3_combined_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.17      0.17      0.17         6\n",
      "         HP       0.20      0.25      0.22         4\n",
      "         LN       0.00      0.00      0.00         2\n",
      "         MN       0.00      0.00      0.00         3\n",
      "         MP       0.33      0.29      0.31         7\n",
      "        Neu       0.38      0.45      0.42        11\n",
      "\n",
      "avg / total       0.25      0.27      0.26        33\n",
      "\n",
      "Accuracy: 0.272727\n",
      "[[1 1 0 0 0 4]\n",
      " [1 1 0 1 0 1]\n",
      " [0 1 0 0 0 1]\n",
      " [0 1 0 0 1 1]\n",
      " [2 1 0 1 2 1]\n",
      " [2 0 0 1 3 5]]\n",
      "\n",
      "Classifying: 3_combined_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       1.00      0.17      0.29         6\n",
      "         HP       0.00      0.00      0.00         4\n",
      "         LN       0.00      0.00      0.00         2\n",
      "         MN       0.00      0.00      0.00         3\n",
      "         MP       0.25      0.71      0.37         7\n",
      "        Neu       0.25      0.18      0.21        11\n",
      "\n",
      "avg / total       0.32      0.24      0.20        33\n",
      "\n",
      "Accuracy: 0.242424\n",
      "[[1 1 0 0 2 2]\n",
      " [0 0 0 0 3 1]\n",
      " [0 0 0 0 2 0]\n",
      " [0 1 0 0 1 1]\n",
      " [0 0 0 0 5 2]\n",
      " [0 2 0 0 7 2]]\n",
      "\n",
      "Classifying: 3_combined_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         6\n",
      "         HP       0.00      0.00      0.00         4\n",
      "         LN       0.00      0.00      0.00         2\n",
      "         MN       0.00      0.00      0.00         3\n",
      "         MP       0.21      1.00      0.35         7\n",
      "        Neu       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.04      0.21      0.07        33\n",
      "\n",
      "Accuracy: 0.212121\n",
      "[[ 0  0  0  0  6  0]\n",
      " [ 0  0  0  0  4  0]\n",
      " [ 0  0  0  0  2  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  0  7  0]\n",
      " [ 0  0  0  0 11  0]]\n",
      "\n",
      "Accuracy after fusion: 0.275862\n"
     ]
    }
   ],
   "source": [
    "Y_AV_cont3, y = classify(X_cont3, Y_combined3, \"3_combined_cont\")\n",
    "Y_AV_cent3, y = classify(X_cent3, Y_combined3, \"3_combined_cent\")\n",
    "Y_AV_geo3, y = classify(X_geo3, Y_combined3, \"3_combined_geo\")\n",
    "Y_AV_face3, y = classify(X_face3, Y_combined3, \"3_combined_lbp\")\n",
    "Y_AV_body3, y = classify(X_body3, Y_combined3, \"3_combined_phog\")\n",
    "newX = np.column_stack((Y_AV_cont3, Y_AV_cent3, Y_AV_geo3, Y_AV_face3, Y_AV_body3))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4+ Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions\n",
      "(69, 30)\n",
      "(69, 3400)\n",
      "(69, 9112)\n",
      "(69, 416)\n",
      "(69, 4064)\n",
      "(69,)\n"
     ]
    }
   ],
   "source": [
    "X_body4 = pd.read_csv(\"./features/4_body_phog_features.csv\").iloc[:, 1:]\n",
    "X_face4 = pd.read_csv(\"./features/4_facial_lbp_features.csv\").iloc[:, 1:]\n",
    "X_geo4 = pd.read_csv(\"./features/4_geo_features.csv\").iloc[:, 1:]\n",
    "X_cont4 = pd.read_csv(\"./features/4_context_features.csv\").iloc[:, 1:]\n",
    "X_cent4 = pd.read_csv(\"./features/4_CENTRIST.csv\").iloc[:, 1:]\n",
    "Y_valence4 = pd.read_csv(\"./labels/4_valence.csv\")[\"V\"]\n",
    "Y_arousal4 = pd.read_csv(\"./labels/4_arousal.csv\")[\"A\"]\n",
    "Y_combined4 = pd.read_csv(\"./labels/4_combined.csv\")[\"AV\"]\n",
    "X_body4 = X_body4.loc[Y_arousal4.notnull()]\n",
    "X_face4 = X_face4.loc[Y_arousal4.notnull()]\n",
    "X_geo4 = X_geo4.loc[Y_arousal4.notnull()]\n",
    "X_cont4 = X_cont4.loc[Y_arousal4.notnull()]\n",
    "X_cent4 = X_cent4.loc[Y_arousal4.notnull()]\n",
    "Y_arousal4 = Y_arousal4.loc[Y_arousal4.notnull()]\n",
    "\n",
    "print \"Dimensions\"\n",
    "print X_cont4.shape\n",
    "print X_body4.shape\n",
    "print X_geo4.shape\n",
    "print X_face4.shape\n",
    "print X_cent4.shape\n",
    "print Y_arousal4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4+ Faces: Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 4_arousal_cont\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.60      0.19      0.29        16\n",
      "          L       0.00      0.00      0.00         0\n",
      "          M       0.80      0.21      0.33        19\n",
      "\n",
      "avg / total       0.71      0.20      0.31        35\n",
      "\n",
      "Accuracy: 0.200000\n",
      "[[ 3 12  1]\n",
      " [ 0  0  0]\n",
      " [ 2 13  4]]\n",
      "\n",
      "Classifying: 4_arousal_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.43      0.56      0.49        16\n",
      "          M       0.50      0.37      0.42        19\n",
      "\n",
      "avg / total       0.47      0.46      0.45        35\n",
      "\n",
      "Accuracy: 0.457143\n",
      "[[ 9  7]\n",
      " [12  7]]\n",
      "\n",
      "Classifying: 4_arousal_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.35      0.38      0.36        16\n",
      "          L       0.00      0.00      0.00         0\n",
      "          M       0.57      0.42      0.48        19\n",
      "\n",
      "avg / total       0.47      0.40      0.43        35\n",
      "\n",
      "Accuracy: 0.400000\n",
      "[[ 6  4  6]\n",
      " [ 0  0  0]\n",
      " [11  0  8]]\n",
      "\n",
      "Classifying: 4_arousal_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.44      0.88      0.58        16\n",
      "          M       0.33      0.05      0.09        19\n",
      "\n",
      "avg / total       0.38      0.43      0.32        35\n",
      "\n",
      "Accuracy: 0.428571\n",
      "[[14  2]\n",
      " [18  1]]\n",
      "\n",
      "Classifying: 4_arousal_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          H       0.46      1.00      0.63        16\n",
      "          M       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.21      0.46      0.29        35\n",
      "\n",
      "Accuracy: 0.457143\n",
      "[[16  0]\n",
      " [19  0]]\n",
      "\n",
      "Accuracy after fusion: 0.551724\n"
     ]
    }
   ],
   "source": [
    "Y_A_cont4, y = classify(X_cont4, Y_arousal4, \"4_arousal_cont\")\n",
    "Y_A_cent4, y = classify(X_cent4, Y_arousal4, \"4_arousal_cent\")\n",
    "Y_A_geo4, y = classify(X_geo4, Y_arousal4, \"4_arousal_geo\")\n",
    "Y_A_face4, y = classify(X_face4, Y_arousal4, \"4_arousal_lbp\")\n",
    "Y_A_body4, y = classify(X_body4, Y_arousal4, \"4_arousal_phog\")\n",
    "# Fused\n",
    "newX = np.column_stack((Y_A_cont4, Y_A_cent4, Y_A_geo4, Y_A_face4, Y_A_body4))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4+ Faces: Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_body4 = pd.read_csv(\"./features/4_body_phog_features.csv\").iloc[:, 1:]\n",
    "X_face4 = pd.read_csv(\"./features/4_facial_lbp_features.csv\").iloc[:, 1:]\n",
    "X_geo4 = pd.read_csv(\"./features/4_geo_features.csv\").iloc[:, 1:]\n",
    "X_cont4 = pd.read_csv(\"./features/4_context_features.csv\").iloc[:, 1:]\n",
    "X_cent4 = pd.read_csv(\"./features/4_CENTRIST.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 4_valence_cont\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.27      0.21      0.24        14\n",
      "        Neu       0.38      0.23      0.29        22\n",
      "          P       0.31      0.53      0.39        17\n",
      "\n",
      "avg / total       0.33      0.32      0.31        53\n",
      "\n",
      "Accuracy: 0.320755\n",
      "[[ 3  1 10]\n",
      " [ 7  5 10]\n",
      " [ 1  7  9]]\n",
      "\n",
      "Classifying: 4_valence_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.33      0.14      0.20        14\n",
      "        Neu       0.53      0.36      0.43        22\n",
      "          P       0.34      0.65      0.45        17\n",
      "\n",
      "avg / total       0.42      0.40      0.38        53\n",
      "\n",
      "Accuracy: 0.396226\n",
      "[[ 2  4  8]\n",
      " [ 1  8 13]\n",
      " [ 3  3 11]]\n",
      "\n",
      "Classifying: 4_valence_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.12      0.14      0.13        14\n",
      "        Neu       0.25      0.23      0.24        22\n",
      "          P       0.35      0.35      0.35        17\n",
      "\n",
      "avg / total       0.25      0.25      0.25        53\n",
      "\n",
      "Accuracy: 0.245283\n",
      "[[ 2  8  4]\n",
      " [10  5  7]\n",
      " [ 4  7  6]]\n",
      "\n",
      "Classifying: 4_valence_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00        14\n",
      "        Neu       0.00      0.00      0.00        22\n",
      "          P       0.32      1.00      0.49        17\n",
      "\n",
      "avg / total       0.10      0.32      0.16        53\n",
      "\n",
      "Accuracy: 0.320755\n",
      "[[ 0  0 14]\n",
      " [ 0  0 22]\n",
      " [ 0  0 17]]\n",
      "\n",
      "Classifying: 4_valence_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          N       0.00      0.00      0.00        14\n",
      "        Neu       0.00      0.00      0.00        22\n",
      "          P       0.32      1.00      0.49        17\n",
      "\n",
      "avg / total       0.10      0.32      0.16        53\n",
      "\n",
      "Accuracy: 0.320755\n",
      "[[ 0  0 14]\n",
      " [ 0  0 22]\n",
      " [ 0  0 17]]\n",
      "\n",
      "Accuracy after fusion: 0.551724\n"
     ]
    }
   ],
   "source": [
    "Y_V_cont4, y = classify(X_cont4, Y_valence4, \"4_valence_cont\")\n",
    "Y_V_cent4, y = classify(X_cent4, Y_valence4, \"4_valence_cent\")\n",
    "Y_V_geo4, y = classify(X_geo4, Y_valence4, \"4_valence_geo\")\n",
    "Y_V_face4, y = classify(X_face4, Y_valence4, \"4_valence_lbp\")\n",
    "Y_V_body4, y = classify(X_body4, Y_valence4, \"4_valence_phog\")\n",
    "# Fused\n",
    "newX = np.column_stack((Y_V_cont4, Y_V_cent4, Y_V_geo4, Y_V_face4, Y_V_body4))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4+ Faces: Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying: 4_combined_cont\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         3\n",
      "         HP       0.00      0.00      0.00         8\n",
      "         LN       0.00      0.00      0.00         1\n",
      "         MN       0.00      0.00      0.00        10\n",
      "         MP       0.00      0.00      0.00         9\n",
      "        Neu       0.38      0.82      0.51        22\n",
      "\n",
      "avg / total       0.16      0.34      0.21        53\n",
      "\n",
      "Accuracy: 0.339623\n",
      "[[ 0  0  0  0  0  3]\n",
      " [ 0  0  0  0  0  8]\n",
      " [ 0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 10]\n",
      " [ 1  0  0  0  0  8]\n",
      " [ 1  3  0  0  0 18]]\n",
      "\n",
      "Classifying: 4_combined_cent\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         3\n",
      "         HP       0.40      0.75      0.52         8\n",
      "         LN       0.00      0.00      0.00         1\n",
      "         MN       0.00      0.00      0.00        10\n",
      "         MP       0.20      0.33      0.25         9\n",
      "        Neu       0.47      0.32      0.38        22\n",
      "\n",
      "avg / total       0.29      0.30      0.28        53\n",
      "\n",
      "Accuracy: 0.301887\n",
      "[[0 1 0 0 1 1]\n",
      " [0 6 2 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [2 1 0 0 3 4]\n",
      " [1 1 1 0 3 3]\n",
      " [2 6 0 0 7 7]]\n",
      "\n",
      "Classifying: 4_combined_geo\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.14      0.33      0.20         3\n",
      "         HP       0.33      0.62      0.43         8\n",
      "         LN       0.00      0.00      0.00         1\n",
      "         MN       0.00      0.00      0.00        10\n",
      "         MP       0.21      0.44      0.29         9\n",
      "        Neu       0.25      0.09      0.13        22\n",
      "\n",
      "avg / total       0.20      0.23      0.18        53\n",
      "\n",
      "Accuracy: 0.226415\n",
      "[[1 0 0 0 2 0]\n",
      " [0 5 1 0 2 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 2 0 0 3 5]\n",
      " [1 2 0 1 4 1]\n",
      " [5 6 1 1 7 2]]\n",
      "\n",
      "Classifying: 4_combined_lbp\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         3\n",
      "         HP       0.17      0.38      0.23         8\n",
      "         LN       0.00      0.00      0.00         1\n",
      "         MN       0.00      0.00      0.00        10\n",
      "         MP       0.12      0.22      0.15         9\n",
      "        Neu       0.50      0.41      0.45        22\n",
      "\n",
      "avg / total       0.25      0.26      0.25        53\n",
      "\n",
      "Accuracy: 0.264151\n",
      "[[0 2 0 0 0 1]\n",
      " [0 3 0 0 4 1]\n",
      " [0 0 0 0 1 0]\n",
      " [0 2 0 0 3 5]\n",
      " [0 5 0 0 2 2]\n",
      " [0 6 0 0 7 9]]\n",
      "\n",
      "Classifying: 4_combined_phog\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         HN       0.00      0.00      0.00         3\n",
      "         HP       0.00      0.00      0.00         8\n",
      "         LN       0.00      0.00      0.00         1\n",
      "         MN       0.00      0.00      0.00        10\n",
      "         MP       0.00      0.00      0.00         9\n",
      "        Neu       0.42      1.00      0.59        22\n",
      "\n",
      "avg / total       0.17      0.42      0.24        53\n",
      "\n",
      "Accuracy: 0.415094\n",
      "[[ 0  0  0  0  0  3]\n",
      " [ 0  0  0  0  0  8]\n",
      " [ 0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 10]\n",
      " [ 0  0  0  0  0  9]\n",
      " [ 0  0  0  0  0 22]]\n",
      "\n",
      "Accuracy after fusion: 0.758621\n"
     ]
    }
   ],
   "source": [
    "Y_AV_cont4, y = classify(X_cont4, Y_combined4, \"4_combined_cont\")\n",
    "Y_AV_cent4, y = classify(X_cent4, Y_combined4, \"4_combined_cent\")\n",
    "Y_AV_geo4, y = classify(X_geo4, Y_combined4, \"4_combined_geo\")\n",
    "Y_AV_face4, y = classify(X_face4, Y_combined4, \"4_combined_lbp\")\n",
    "Y_AV_body4, y = classify(X_body4, Y_combined4, \"4_combined_phog\")\n",
    "newX = np.column_stack((Y_AV_cont4, Y_AV_cent4, Y_AV_geo4, Y_AV_face4, Y_AV_body4))\n",
    "print \"Accuracy after fusion: %f\" % fusion(newX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
